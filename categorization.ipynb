{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Connection succesful.\n"
     ]
    }
   ],
   "source": [
    "from db_connection import DB_Connection\n",
    "import pandas as pd, numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.widgets import TextBox\n",
    "import re, json\n",
    "from wordcloud import WordCloud\n",
    "import Tweet\n",
    "\n",
    "\n",
    "db = DB_Connection()\n",
    "\n",
    "database = db.query('''SELECT * FROM TWTTWEET WHERE TWEET_CREATED<'2021-01-01'\n",
    "                    ORDER BY TWEET_CREATED DESC;''')\n",
    "df = pd.DataFrame(database, columns=['id','userid','text','date',\n",
    "                            'link','media1','media2','media3', 'media4'])\n",
    "df = df.loc[:, ['id', 'text']]\n",
    "\n",
    "\n",
    "processed = Tweet.clean_text(df, 'text')\n",
    "classified = Tweet.classify_text(processed, 'clean')\n",
    "\n",
    "# incidents = classified[['id','isIncident']].groupby('isIncident').size()\n",
    "# accidents = classified[['id','isAccident']].groupby('isAccident').size()[1]\n",
    "# dangers = classified[['id','isDanger']].groupby('isDanger').size()[1]\n",
    "# obstacles = classified[['id','isObstacle']].groupby('isObstacle').size()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = ' '.join([t for t in classified.clean])\n",
    "joined = joined.split()\n",
    "new_joined = pd.Series(joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_joined.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [0,1,2]\n",
    "data = [accidents,obstacles,dangers]\n",
    "plt.figure(figsize=(10,6))\n",
    "g = sns.barplot(x=x, y=data)\n",
    "plt.title('% de incidentes por categoría', fontsize=16)\n",
    "plt.xticks(ticks=x,\n",
    "        labels=['accidentes','obstáculos','peligros'],\n",
    "        fontsize=13)\n",
    "plt.ylim(top=65000)\n",
    "\n",
    "for i, v in enumerate(data):\n",
    "    g.text(i, v+1000, v, color='black', ha=\"center\", fontsize=12)\n",
    "    # plt.annotate(v, (i+3, 10), color='black', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Text classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer1 = CountVectorizer(max_features=600, min_df=5, max_df=0.7)\n",
    "X11 = vectorizer1.fit_transform(classified.clean).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf = TfidfTransformer()\n",
    "X2 = tfidf.fit_transform(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfi = TfidfVectorizer(sublinear_tf=True, max_features=500, min_df=5, max_df=0.7, encoding='utf-8', ngram_range=(1,2))\n",
    "X3 = tfi.fit_transform(classified.clean).toarray()\n",
    "# labels = classified.isIncident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [i for i in classified[['isAccident','isObstacle','isDanger']].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X11, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "source": [
    "### Boosting Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "start = time.time()\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print('Duration:', str(end-start))\n",
    "\n",
    "y_xgb = xgb.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_xgb))\n",
    "print(classification_report(y_test,y_xgb))\n",
    "print(accuracy_score(y_test, y_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgresume = []\n",
    "\n",
    "for i in [64,128,256,512,1024,2048,4096]:\n",
    "    print('\\nestimators:', str(i))\n",
    "    start = time.time()\n",
    "    xgb = XGBClassifier(n_estimators=i, learning_rate=0.3, eval_metric='error') # learning_rate\n",
    "    xgb.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    y_xgb = xgb.predict(X_test)\n",
    "    print(str(end-start), accuracy_score(y_test, y_xgb))\n",
    "    xgresume.append([i, end-start, accuracy_score(y_test, y_xgb),\n",
    "    confusion_matrix(y_test,y_xgb), classification_report(y_test,y_xgb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [i[0] for i in xgresume]\n",
    "ys = [i[2] for i in xgresume]\n",
    "zs = [i[3] for i in xgresume]\n",
    "\n",
    "plt.figure(figsize=(11,4))\n",
    "plt.title('XGBoost')\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.pointplot(x=xs, y=ys)\n",
    "# sns.lineplot(x=range(len(xs)), y=ys, markers=True, style='event')\n",
    "plt.title('Duración de entrenamiento')\n",
    "plt.xticks(range(len(xs)), xs)\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.pointplot(x=xs, y=zs)\n",
    "plt.title('Precisión obtenida')\n",
    "plt.xticks(range(len(xs)), xs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "6813.413553237915\n"
     ]
    }
   ],
   "source": [
    "param_test0 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "gsearch0 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.3, n_estimators=100, max_depth=6,\n",
    "                                        min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1, \n",
    "                                        eval_metric='error', seed=27), \n",
    "                        param_grid = param_test0, scoring='accuracy',n_jobs=4, cv=3, verbose=2)\n",
    "grid_result0 = MultiOutputClassifier(gsearch0).fit(X_train1, y_train1)\n",
    "end = time.time()\n",
    "print(str(end-start))\n",
    "with open('param_test0', 'wb') as picklefile:\n",
    "    pickle.dump(grid_result0, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    grid_results0 = pd.DataFrame(grid_result0.estimators_[i].cv_results_)\n",
    "    grid_results0.to_csv('grid_results0-%d.csv'%(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'min_child_weight': 1}"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "grid_result0.estimators_[2].cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    " 'gamma':[i/10.0 for i in range(0,4)]\n",
    "}\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.3, n_estimators=100,\n",
    "                                        max_depth=gsearch0.best_params_.['max_depth'],\n",
    "                                        min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    "                        param_grid = param_test1, scoring='accuracy',n_jobs=4, cv=3, verbose=3)\n",
    "gsearch1.fit(X_train1, y_train1)\n",
    "gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test2 = {\n",
    " 'subsample':[i/10.0 for i in range(6,11)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,11)]\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.3, n_estimators=100, max_depth=9,\n",
    "                                        min_child_weight=1, gamma=0.1, subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    "                        param_grid = param_test2, scoring='accuracy',n_jobs=4, cv=3, verbose=3)\n",
    "gsearch2.fit(X_train1, y_train1)\n",
    "gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test4 = {\n",
    " 'subsample':[i/10.0 for i in range(8,11)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(8,11)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.3, n_estimators=100, max_depth=9,\n",
    "                                        min_child_weight=1, gamma=0.1, subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    "                        param_grid = param_test4, scoring='accuracy',n_jobs=4, cv=3, verbose=1)\n",
    "gsearch4.fit(X_train1, y_train1)\n",
    "gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test3 = {\n",
    " 'reg_alpha':[0, 1e-5, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "}\n",
    "\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.3, n_estimators=100, max_depth=9,\n",
    "                                        min_child_weight=1, gamma=0.1, subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    "                        param_grid = param_test3, scoring='accuracy',n_jobs=4, cv=3, verbose=3)\n",
    "gsearch3.fit(X_train1, y_train1)\n",
    "gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results3 = pd.DataFrame(gsearch3.cv_results_)\n",
    "grid_results3.sort_values('rank_test_score').head(5)#[['rank_test_score','param_colsample_bytree', 'param_subsample', 'mean_test_score', 'std_test_score']].rename(columns={'param_colsample_bytree':'colsample_bytree', 'param_param_subsample':'subsample'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results3.to_csv('grid_search_results3-4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(\n",
    "    learning_rate=0.3,\n",
    "    n_estimators=2000,\n",
    "    max_depth=9, min_child_weight=1,\n",
    "    gamma=0.1, subsample=0.9, colsample_bytree=1,\n",
    "    nthread=4, seed=27, verbosity=3)\n",
    "\n",
    "xgb_param = xgb1.get_xgb_params()\n",
    "xgtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=xgb1.get_params()['n_estimators'], nfold=5,\n",
    "    early_stopping_rounds=50)\n",
    "xgb1.set_params(n_estimators=cvresult.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the algorithm on the data\n",
    "print('Start training.')\n",
    "start = time.time()\n",
    "xgb1.fit(X_train, y_train, verbose=True)\n",
    "print('End training.') \n",
    "end = time.time()\n",
    "    \n",
    "#Predict training set:\n",
    "dtrain_predictions = xgb1.predict(X_test)\n",
    "dtrain_predprob = xgb1.predict_proba(X_test)[:,1]\n",
    "    \n",
    "#Print model report:\n",
    "print(\"\\nModel Report\")\n",
    "print(\"Duration:\", str(end-start))\n",
    "print(\"Accuracy : %.4g\" % metrics.accuracy_score(y_test, dtrain_predictions))\n",
    "print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(y_test, dtrain_predprob))\n",
    "                \n",
    "plt.figure(figsize=(15,5))\n",
    "feat_imp = pd.Series(xgb1.get_booster().get_fscore()).sort_values(ascending=False)\n",
    "feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "source": [
    "#### Estimators adjust"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgresume = []\n",
    "xgb_arr = []\n",
    "\n",
    "for i in [512,1024,2048]:\n",
    "    print('\\nestimators:', str(i))\n",
    "    start = time.time()\n",
    "    xgb = XGBClassifier(\n",
    "        learning_rate=0.3,\n",
    "        n_estimators=i,\n",
    "        max_depth=9, min_child_weight=1,\n",
    "        gamma=0.1, subsample=0.8, colsample_bytree=0.8,\n",
    "        reg_alpha=0.005,\n",
    "        nthread=4, seed=27, eval_metric='error', verbosity=0)\n",
    "    xgb_arr.append(xgb)\n",
    "    print('Fitting... ', time.asctime())\n",
    "    xgb_arr[-1].fit(X_train1, y_train1)\n",
    "    end = time.time()\n",
    "    print('Predicting... ', time.asctime())\n",
    "    y_xgb = xgb_arr[-1].predict(X_test1)\n",
    "    print(str(end-start), accuracy_score(y_test1, y_xgb))\n",
    "    xgresume.append([i, end-start, accuracy_score(y_test1, y_xgb),\n",
    "    confusion_matrix(y_test1,y_xgb), classification_report(y_test1,y_xgb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in xgresume:\n",
    "    for s in i: print(s)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [i[0] for i in xgresume]\n",
    "ys = [i[1] for i in xgresume]\n",
    "zs = [i[2] for i in xgresume]\n",
    "\n",
    "plt.figure(figsize=(9,3.5))\n",
    "plt.suptitle('Resultados del ajuste de número de estimados', fontsize=16)\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.pointplot(x=xs, y=ys)\n",
    "plt.title('Duración de entrenamiento')\n",
    "plt.xticks(range(len(xs)), xs)\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.pointplot(x=xs, y=zs)\n",
    "plt.title('Precisión obtenida')\n",
    "plt.xticks(range(len(xs)), xs)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('xgbresume0', 'wb') as picklefile:\n",
    "    pickle.dump(xgresume, picklefile)\n",
    "with open('xgbarr0', 'wb') as picklefile:\n",
    "    pickle.dump(xgb_arr, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgresume1 = []\n",
    "xgb_arr1 = []\n",
    "\n",
    "for i in [600,700,800,900]:\n",
    "    print('\\nestimators:', str(i))\n",
    "    start = time.time()\n",
    "    xgb = XGBClassifier(\n",
    "        learning_rate=0.3,\n",
    "        n_estimators=i,\n",
    "        max_depth=9, min_child_weight=1,\n",
    "        gamma=0.1, subsample=0.8, colsample_bytree=0.8,\n",
    "        reg_alpha=0.005,\n",
    "        nthread=4, seed=27, eval_metric='error', verbosity=0)\n",
    "    xgb_arr1.append(xgb)\n",
    "    xgb_arr1[-1].fit(X_train1, y_train1)\n",
    "    end = time.time()\n",
    "    y_xgb = xgb_arr1[-1].predict(X_test1)\n",
    "    print(str(end-start), accuracy_score(y_test1, y_xgb))\n",
    "    xgresume1.append([i, end-start, accuracy_score(y_test1, y_xgb),\n",
    "    confusion_matrix(y_test1,y_xgb), classification_report(y_test1,y_xgb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in xgresume1:\n",
    "    for s in i: print(s)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i[0] for i in xgresume1] + [xgresume[1][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [i[0] for i in xgresume1] + [xgresume[1][0]]\n",
    "ys = [i[1] for i in xgresume1] + [xgresume[1][1]]\n",
    "zs = [i[2] for i in xgresume1] + [xgresume[1][2]]\n",
    "\n",
    "plt.figure(figsize=(8.5,3.5))\n",
    "plt.suptitle('Resultados del subajuste de número de estimados', fontsize=16)\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.pointplot(x=xs, y=ys)\n",
    "plt.title('Duración de entrenamiento')\n",
    "plt.xticks(range(len(xs)), xs)\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.pointplot(x=xs, y=zs)\n",
    "plt.title('Precisión obtenida')\n",
    "plt.xticks(range(len(xs)), xs)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('xgbresume1', 'wb') as picklefile:\n",
    "    pickle.dump(xgresume1, picklefile)\n",
    "with open('xgbarr1', 'wb') as picklefile:\n",
    "    pickle.dump(xgb_arr1, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nestimators: 1000')\n",
    "start = time.time()\n",
    "xgb_final = XGBClassifier(\n",
    "    learning_rate=0.3,\n",
    "    n_estimators=1000,\n",
    "    max_depth=9, min_child_weight=1,\n",
    "    gamma=0.1, subsample=0.8, colsample_bytree=0.8, reg_alpha=0.005,\n",
    "    nthread=4, seed=27, eval_metric='error', verbosity=0)\n",
    "xgb_final.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "y_xgb = xgb_final.predict(X_test)\n",
    "print(str(end-start), accuracy_score(y_test, y_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_final = xgb_arr1[-1]\n",
    "y_xgb = xgb_final.predict(X_test1)\n",
    "xgb_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_con = confusion_matrix(y_test1,y_xgb)\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = ['{0:0.0f}'.format(value) for value in\n",
    "                xgb_con.flatten()]\n",
    "group_percentages = ['{0:.2%}'.format(value) for value in\n",
    "                     xgb_con.flatten()/np.sum(xgb_con)]\n",
    "labels = ['%s\\n%s\\n%s' % (v1, v2, v3) for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "plt.figure(figsize=(6,3.2))\n",
    "sns.heatmap(xgb_con/np.sum(xgb_con), annot=labels, fmt='', cmap='Blues')\n",
    "plt.title('Matriz de confusión para 900 estimados', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('xgb_classifier', 'wb') as picklefile:\n",
    "    pickle.dump(xgb_final, picklefile)"
   ]
  },
  {
   "source": [
    "#### Count vectors adjust"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "with open('xgb_classifier', 'rb') as training_model:\n",
    "    xgb = pickle.load(training_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xgresume2 = []\n",
    "xgb_arr2 = []\n",
    "\n",
    "for i in [800, 1000, 2000, 5000, 10000]:\n",
    "    print('\\nnumber of features:', str(i))\n",
    "    vectorizer = CountVectorizer(max_features=i, min_df=5, max_df=0.7)\n",
    "    print('Fitting vectorizer...')\n",
    "    X1 = vectorizer.fit_transform(classified.clean).toarray()\n",
    "    print('Creating train-test data...')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X1, classified.isIncident, test_size=0.2, random_state=0)\n",
    "    print('Fitting model...', time.asctime())\n",
    "    with open('xgb_classifier', 'rb') as training_model:\n",
    "        xgb_arr2.append(pickle.load(training_model))\n",
    "    start = time.time()\n",
    "    xgb_arr2[-1].fit(X_train,y_train)\n",
    "    end = time.time()\n",
    "    print('Fitting time:', str(end-start), '\\nPredicting...')\n",
    "    y_xgb = xgb_arr2[-1].predict(X_test)\n",
    "    print(accuracy_score(y_test, y_xgb))\n",
    "    print(confusion_matrix(y_test,y_xgb))\n",
    "    print(classification_report(y_test,y_xgb))\n",
    "    xgresume2.append([i, end-start, accuracy_score(y_test, y_xgb),\n",
    "    confusion_matrix(y_test,y_xgb), classification_report(y_test,y_xgb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('xgbresume2', 'wb') as picklefile:\n",
    "    pickle.dump(xgresume2, picklefile)\n",
    "with open('xgbarr2', 'wb') as picklefile:\n",
    "    pickle.dump(xgb_arr2, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "with open('./others/resumes/xgbarr2', 'rb') as arr:\n",
    "    xgb_arr2 = pickle.load(arr)\n",
    "with open('./others/resumes/xgbresume2', 'rb') as resume:\n",
    "    xgresume2 = pickle.load(resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [i[0] for i in xgresume2]\n",
    "ys = [i[1] for i in xgresume2]\n",
    "zs = [i[2] for i in xgresume2]\n",
    "\n",
    "plt.figure(figsize=(9,3.5))\n",
    "plt.suptitle('Resultados del ajuste de número de vectores', fontsize=16)\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.pointplot(x=xs, y=ys)\n",
    "plt.title('Duración de entrenamiento')\n",
    "plt.xticks(range(len(xs)), xs)\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.pointplot(x=xs, y=zs)\n",
    "plt.title('Precisión obtenida')\n",
    "plt.xticks(range(len(xs)), xs)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save final xgb model\n",
    "xgb_final2 = xgb_arr2[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit vectorizer 5000 features\n",
    "i = 5000\n",
    "print('\\nnumber of features:', str(i))\n",
    "vectorizer10 = CountVectorizer(max_features=i, min_df=5, max_df=0.7)\n",
    "print('Fitting vectorizer...', time.asctime())\n",
    "vectorizer10.fit(classified.clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert and split data\n",
    "X_vect = vect.transform(classified.clean).toarray()\n",
    "print('Creating train-test data...')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vect, classified.isIncident, test_size=0.2, random_state=0)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vectorizer5000', 'wb') as picklefile:\n",
    "    pickle.dump(vectorizer10, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model fo 5000 features\n",
    "with open('count_vectorizer', 'rb') as v:\n",
    "    vect = pickle.load(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "with open('xgb_5000', 'rb') as training_model:\n",
    "    xgb_classifier = pickle.load(training_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit classifier with 5000 features\n",
    "print('Fitting model...', time.asctime())\n",
    "start = time.time()\n",
    "xgb_classifier.fit(X_train,y_train)\n",
    "end = time.time()\n",
    "print('Fitting time:', str(end-start), '\\nPredicting...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test data\n",
    "print('Predicting data...')\n",
    "y_xgb2 = xgb_classifier.predict(X_test)\n",
    "print(accuracy_score(y_test, y_xgb2))\n",
    "print(confusion_matrix(y_test,y_xgb2))\n",
    "print(classification_report(y_test,y_xgb2))\n",
    "# xgresume2.append([i, end-start, accuracy_score(y_test, y_xgb2),\n",
    "# confusion_matrix(y_test,y_xgb2), classification_report(y_test,y_xgb2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained classifier\n",
    "with open('xgb_features_final', 'wb') as picklefile:\n",
    "    pickle.dump(xgb_classifier, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count vectors for 10000\n",
    "i = 10000\n",
    "print('\\nnumber of features:', str(i))\n",
    "vectorizer100 = CountVectorizer(max_features=i, min_df=5, max_df=0.7)\n",
    "print('Fitting vectorizer...', time.asctime())\n",
    "vectorizer100.fit(classified.clean)\n",
    "X_vect1 = vectorizer100.transform(classified.clean).toarray()\n",
    "print('Creating train-test data...')\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X_vect1, classified.isIncident, test_size=0.2, random_state=0)\n",
    "with open('vectorizer10000', 'wb') as picklefile:\n",
    "    pickle.dump(vectorizer100, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting 10000 vectors\n",
    "#load model\n",
    "with open('xgb_classifier', 'rb') as model:\n",
    "    xgb_classifier1 = pickle.load(model)\n",
    "print('Fitting model...', time.asctime())\n",
    "start = time.time()\n",
    "xgb_classifier1.fit(X_train3,y_train3)\n",
    "end = time.time()\n",
    "print('Fitting time:', str(end-start), '\\nPredicting...')\n",
    "y_xgb3 = xgb_classifier1.predict(X_test3)\n",
    "print(accuracy_score(y_test3, y_xgb3))\n",
    "print(confusion_matrix(y_test3,y_xgb3))\n",
    "print(classification_report(y_test3,y_xgb3))\n",
    "# xgresume2.append([i, end-start, accuracy_score(y_test, y_xgb3),\n",
    "# confusion_matrix(y_test,y_xgb3), classification_report(y_test,y_xgb3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_con = confusion_matrix(y_test,y_xgb2)\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = ['{0:0.0f}'.format(value) for value in\n",
    "                xgb_con.flatten()]\n",
    "group_percentages = ['{0:.2%}'.format(value) for value in\n",
    "                     xgb_con.flatten()/np.sum(xgb_con)]\n",
    "labels = ['%s\\n%s\\n%s' % (v1, v2, v3) for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "plt.figure(figsize=(6,3.2))\n",
    "sns.heatmap(xgb_con/np.sum(xgb_con), annot=labels, fmt='', cmap='Blues')\n",
    "plt.title('Matriz de confusión para 5000 características', fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df = pd.DataFrame(X_vect)\n",
    "feat_df.columns = vect.get_feature_names()\n",
    "\n",
    "plt.figure(figsize=(10,3.5))\n",
    "feat_imp = pd.Series(xgb_classifier.get_booster().get_fscore()).sort_values(ascending=False)[:40]\n",
    "# feat_imp.plot(kind='bar', title='Feature] Importances')\n",
    "feat_values = [int(re.sub('f', '', i)) for i in feat_imp.index]\n",
    "feat_names = [feat_df.columns[i] for i in feat_values]\n",
    "features = pd.DataFrame({'feature_num':feat_values, 'names':feat_names, 'count':feat_imp.values})\n",
    "# plt.bar(x=feat_values, height=feat_imp.values)\n",
    "# sns.barplot(x=feat_values, y=feat_imp.values, data=feat_imp, order=feat_imp.values)\n",
    "plt.suptitle('Importancia de características', fontsize=16)\n",
    "# plt.subplot(2, 1, 1)\n",
    "sns.barplot(x='names', y='count', data=features)\n",
    "plt.xticks(rotation=70, fontsize=12, ha='right')\n",
    "plt.ylabel('Puntaje de características', fontsize=12)\n",
    "# plt.tight_layout()\n",
    "plt.xlabel(None)"
   ]
  }
 ]
}