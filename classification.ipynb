{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from db_connection import DB_Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import TextBox\n",
    "import re, json\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Connection succesful.\n"
     ]
    }
   ],
   "source": [
    "db = DB_Connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(database, columns=['id','userid','username','text','date',\n",
    "                            'link','media1','media2','media3', 'media4'])\n",
    "df_clean = df[:]\n",
    "df_clean = df_clean[df_clean.text!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the tweets\n",
    "stop_words = json.load(open('./others/stop_words.json', encoding='utf8'))\n",
    "def preprocess(tweet):\n",
    "    # remove next lines\n",
    "    tweet = re.sub('\\n', ' ', tweet)\n",
    "    # remove links\n",
    "    tweet = re.sub('http\\S+\\s*', '', tweet)\n",
    "    # remove between parentesis\n",
    "    tweet = re.sub('\\[.*\\]','', tweet)\n",
    "    # remove mentions\n",
    "    tweet = re.sub(\"@\\w+\", \"\", tweet)\n",
    "    # remove hashtags\n",
    "    tweet = re.sub(\"#\\w+\", \"\", tweet)\n",
    "    # alphanumeric and hashtags\n",
    "    tweet = re.sub(\"[^a-zA-Z0-9ñáéíóúÁÉÍÓÚüÜ]\", \" \", tweet)\n",
    "    # remove multiple spaces\n",
    "    tweet = re.sub(\"\\s+\", \" \", tweet)\n",
    "    tweet = re.sub('^\\s+', '', tweet)\n",
    "    # lower first character\n",
    "    try: tweet = tweet[0].lower() + tweet[1:]\n",
    "    except: pass\n",
    "    # remove stop words\n",
    "    tweet = ' '.join([word for word in tweet.split(' ') \n",
    "                if not word.lower() in stop_words])\n",
    "\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_processed = pd.DataFrame(columns=['id','text','clean','place','coords'])\n",
    "df_processed = df_clean.loc[:, ['id', 'text']]\n",
    "df_processed['clean'] = df_processed.text\n",
    "df_processed['clean'] = df_processed.apply(lambda row: preprocess(row.clean), axis=1)\n",
    "# for row in df:\n",
    "#     index = len(df_processed)\n",
    "#     print(row)\n",
    "#     df_processed.iloc[index, 'id'] = row[0]\n",
    "#     df_processed.iloc[index, 'text'] = row[3]\n",
    "#     clean_twt = preprocess(row[3])\n",
    "#     df_processed.iloc[index, 'clean'] = clean_twt\n",
    "#     df_processed.iloc[index, 'place'] = get_geoloc(clean_twt)\n",
    "\n",
    "# df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_processed[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['isAccident'] = np.where(df2.clean.str.contains('accidente|accidentaron|accidentó|choque|chocó|chocaron|choca|chocar|colisión|colisionaron|colisionó|colisiona|colisionado|vuelco|volcó|vuelca|atropello|atropellado'), 1, 0)\n",
    "\n",
    "df2['isObstacle'] = np.where(df2.clean.str.contains('tranque|trancado|embotellamiento|desplazan autos|vistas tráfico|movimiento vehicular|huelga|motín|protesta|protestando|trabajos vía|trabajos|trabajos ruta|cierre|cerraron|cerrado|cierran|cierra|daño|dañó|detuvieron|detenido|detenida|obstáculo|obstaculizando|parado|paro|paño cerrado|tráfico paralizado|tráfico detenido|tráfico afectado|tráfico pesado|tráfico lento|desvío|área acordonada'), 1, 0)\n",
    "\n",
    "df2['isDanger'] = np.where(df2.clean.str.contains('incendio|incendia|incendiando|incendiado|incendiaron|inundado|inundación|inundó'), 1, 0)\n",
    "\n",
    "df2['isIncident'] = np.where(df2[['isAccident','isObstacle','isDanger']].sum(axis=1)>0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['place'] = df2.apply(lambda row: get_place(row.clean) if row.isIncident==1 else '', axis=1)\n",
    "\n",
    "# df2[['lat','long']] = df2.apply(lambda row: get_place(row.clean) if row.isIncident==1 else '', axis=1)"
   ]
  }
 ]
}