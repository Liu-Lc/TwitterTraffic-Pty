{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python380jvsc74a57bd039897e887fdcf105827cc0646dea5514e7d787d0b8d213f1a5227514ffbfb4c6",
   "display_name": "Python 3.8.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "39897e887fdcf105827cc0646dea5514e7d787d0b8d213f1a5227514ffbfb4c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Process\n",
    "\n",
    "- The system launchs\n",
    "- Updater runs\n",
    "    - Each one is passed through detection, stored in DB\n",
    "    - Show few tweets from the day\n",
    "- Dashboard shows\n",
    "- Streaming runs\n",
    "\n",
    "## What happens when a tweet is found is analyzed in this notebook\n",
    "\n",
    "What has to be done:\n",
    "- store the tweets id\n",
    "- clean text?\n",
    "- get the model to detect it and classify it if its true\n",
    "  - set the place (not included still)\n",
    "- insert into twtincidents if its an incident with classification (and place)\n",
    "- send information to frontend and load the tweet in the dashboard (info and map)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Updater\n",
    "import pandas as pd\n",
    "import Detection\n",
    "import Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "181485"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# First add everything to twtincident table\n",
    "from DBConnect import DB_Connection\n",
    "db = DB_Connection()\n",
    "db.connect()\n",
    "twt = db.query_all()\n",
    "len(twt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1391853785857859593,\n",
       " 'TraficoCPanama',\n",
       " 'Tráfico Panamá',\n",
       " 'Se registra accidente de tránsito en la Vía Transístmica, próximo a La Cabima precaución en esta ruta. https://t.co/m6xUDtyb6g',\n",
       " datetime.datetime(2021, 5, 10, 20, 32, 56, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=-300, name=None)),\n",
       " 'https://www.twitter.com/TraficoCPanama/status/1391853785857859593')"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "twt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "twt_df = pd.DataFrame(twt, columns=['tweetid','user_id','user_name','text','created_at','link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all classification\n",
    "twt_df = Detection.get_classifications(twt_df,'text') # [twt_df.id>1383930855978979331]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class incident to add to DB\n",
    "class Incident:\n",
    "    def __init__(self, tweetid, place, isAccident, isObstacle, isDanger):\n",
    "        self.tweetid = tweetid\n",
    "        self.place = place\n",
    "        self.isAccident = isAccident\n",
    "        self.isObstacle = isObstacle\n",
    "        self.isDanger = isDanger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## iterate through each incident\n",
    "for index, row in twt_df[twt_df.isIncident==1].iterrows():\n",
    "    # create object with respective attributes\n",
    "    i = Incident(row.tweetid, None, \n",
    "        True if row.isAccident==1 else False, \n",
    "        True if row.isObstacle==1 else False, \n",
    "        True if row.isDanger==1 else False)\n",
    "    # insert to DB (on conflict do nothing)\n",
    "    db.insert_incident(i)\n",
    "    # print('Inserted - ', index)"
   ]
  },
  {
   "source": [
    "## Updater tweepy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# First add everything to twtincident table\n",
    "from DBConnect import DB_Connection\n",
    "db = DB_Connection()\n",
    "db.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get last date and format it\n",
    "last_date = db.query_date()\n",
    "last_date = (last_date - timedelta(days=1)).strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.2506520748138428 54\n"
     ]
    }
   ],
   "source": [
    "# get last week tweets\n",
    "start = time.time()\n",
    "past_tweets = Updater.get_tweets(from_date=last_date)\n",
    "end = time.time()\n",
    "print(end - start, len(past_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get tweets to dataframe\n",
    "# dict gets a dictionary of attributes and values\n",
    "data = pd.DataFrame([i.__dict__ for i in past_tweets])\n",
    "## get classification and category of each tweet\n",
    "data = Detection.get_classifications(data, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1391853785857859593"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "## gets max id (lastest tweet)\n",
    "# this is to only process new tweets\n",
    "last_id = db.query('SELECT max(inc_tweet_id) FROM public.twtincident;')[0][0]\n",
    "last_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## iterates through new tweets\n",
    "for index, row in data[data.tweetid>last_id].iterrows():\n",
    "    # inserts tweet to db\n",
    "    db.insert_tweet(row)\n",
    "    print('Inserted - ', index)\n",
    "    # if the tweet is accident, inserts to database\n",
    "    if row.isIncident==1:\n",
    "        i = Incident(row.tweetid, None, True if row.isAccident==1 else False, True if row.isObstacle==1 else False, True if row.isDanger==1 else False)\n",
    "        db.insert_incident(i)\n",
    "        print('Incident')"
   ]
  },
  {
   "source": [
    "## Streaming\n",
    "\n",
    "What has to be done:\n",
    "- store the tweets id\n",
    "- clean text?\n",
    "- get the model to detect it and classify it if its true\n",
    "  - set the place (not included still)\n",
    "- insert into twtincidents if its an incident with classification (and place)\n",
    "- send information to frontend and load the tweet in the dashboard (info and map)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}