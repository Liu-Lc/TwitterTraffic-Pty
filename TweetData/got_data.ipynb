{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "39897e887fdcf105827cc0646dea5514e7d787d0b8d213f1a5227514ffbfb4c6"
   }
  },
  "interpreter": {
   "hash": "39897e887fdcf105827cc0646dea5514e7d787d0b8d213f1a5227514ffbfb4c6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Process\n",
    "\n",
    "- The system launchs\n",
    "- Updater runs\n",
    "    - Each one is passed through detection, stored in DB\n",
    "    - Show few tweets from the day\n",
    "- Dashboard shows\n",
    "- Streaming runs\n",
    "\n",
    "## What happens when a tweet is found is analyzed in this notebook\n",
    "\n",
    "What has to be done:\n",
    "- store the tweets id\n",
    "- clean text?\n",
    "- get the model to detect it and classify it if its true\n",
    "  - set the place (not included still)\n",
    "- insert into twtincidents if its an incident with classification (and place)\n",
    "- send information to frontend and load the tweet in the dashboard (info and map)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import Updater\r\n",
    "import pandas as pd\r\n",
    "import Detection\r\n",
    "import Preprocessing"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './models/vectorizer3000'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-441cc46b801f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mUpdater\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mDetection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPreprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lucia\\OneDrive - Universidad Tecnológica de Panamá\\Proyectos-Articulos\\Tesis\\code\\TwitterTraffic-Pty\\TweetData\\Detection.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# load  vectorizers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./models/vectorizer3000'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mvect1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mvectorizer3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvect1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./models/vectorizer10000'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mvect2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './models/vectorizer3000'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# First add everything to twtincident table\r\n",
    "from DBConnect import DB_Connection\r\n",
    "db = DB_Connection()\r\n",
    "db.connect()\r\n",
    "twt = db.query_all()\r\n",
    "len(twt)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "181485"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "twt[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1391853785857859593,\n",
       " 'TraficoCPanama',\n",
       " 'Tráfico Panamá',\n",
       " 'Se registra accidente de tránsito en la Vía Transístmica, próximo a La Cabima precaución en esta ruta. https://t.co/m6xUDtyb6g',\n",
       " datetime.datetime(2021, 5, 10, 20, 32, 56, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=-300, name=None)),\n",
       " 'https://www.twitter.com/TraficoCPanama/status/1391853785857859593')"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "twt_df = pd.DataFrame(twt, columns=['tweetid','user_id','user_name','text','created_at','link'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# Get all classification\r\n",
    "twt_df = Detection.get_classifications(twt_df,'text') # [twt_df.id>1383930855978979331]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# class incident to add to DB\r\n",
    "class Incident:\r\n",
    "    def __init__(self, tweetid, place, isAccident, isObstacle, isDanger):\r\n",
    "        self.tweetid = tweetid\r\n",
    "        self.place = place\r\n",
    "        self.isAccident = isAccident\r\n",
    "        self.isObstacle = isObstacle\r\n",
    "        self.isDanger = isDanger"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "## iterate through each incident\r\n",
    "for index, row in twt_df[twt_df.isIncident==1].iterrows():\r\n",
    "    # create object with respective attributes\r\n",
    "    i = Incident(row.tweetid, None, \r\n",
    "        True if row.isAccident==1 else False, \r\n",
    "        True if row.isObstacle==1 else False, \r\n",
    "        True if row.isDanger==1 else False)\r\n",
    "    # insert to DB (on conflict do nothing)\r\n",
    "    db.insert_incident(i)\r\n",
    "    # print('Inserted - ', index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Updater tweepy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import time\r\n",
    "from datetime import timedelta"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# First add everything to twtincident table\r\n",
    "from DBConnect import DB_Connection\r\n",
    "db = DB_Connection()\r\n",
    "db.connect()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# get last date and format it\r\n",
    "last_date = db.query_date()\r\n",
    "last_date = (last_date - timedelta(days=1)).strftime('%Y-%m-%d')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# get last week tweets\r\n",
    "start = time.time()\r\n",
    "past_tweets = Updater.get_tweets(from_date=last_date)\r\n",
    "end = time.time()\r\n",
    "print(end - start, len(past_tweets))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.2506520748138428 54\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "## get tweets to dataframe\r\n",
    "# dict gets a dictionary of attributes and values\r\n",
    "data = pd.DataFrame([i.__dict__ for i in past_tweets])\r\n",
    "## get classification and category of each tweet\r\n",
    "data = Detection.get_classifications(data, 'text')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "## gets max id (lastest tweet)\r\n",
    "# this is to only process new tweets\r\n",
    "last_id = db.query('SELECT max(inc_tweet_id) FROM public.twtincident;')[0][0]\r\n",
    "last_id"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1391853785857859593"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "## iterates through new tweets\r\n",
    "for index, row in data[data.tweetid>last_id].iterrows():\r\n",
    "    # inserts tweet to db\r\n",
    "    db.insert_tweet(row)\r\n",
    "    print('Inserted - ', index)\r\n",
    "    # if the tweet is accident, inserts to database\r\n",
    "    if row.isIncident==1:\r\n",
    "        i = Incident(row.tweetid, None, True if row.isAccident==1 else False, True if row.isObstacle==1 else False, True if row.isDanger==1 else False)\r\n",
    "        db.insert_incident(i)\r\n",
    "        print('Incident')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Streaming\r\n",
    "\r\n",
    "What has to be done:\r\n",
    "- store the tweets id\r\n",
    "- clean text?\r\n",
    "- get the model to detect it and classify it if its true\r\n",
    "  - set the place (not included still)\r\n",
    "- insert into twtincidents if its an incident with classification (and place)\r\n",
    "- send information to frontend and load the tweet in the dashboard (info and map)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df1 = pd.read_csv('tweets-2016-2017-clean.csv', encoding='utf-8')\r\n",
    "df2 = pd.read_csv('tweets-2018-2020-clean.csv', encoding='utf-8')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "df1.head(1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>isincident</th>\n",
       "      <th>isaccident</th>\n",
       "      <th>isobstacle</th>\n",
       "      <th>isdanger</th>\n",
       "      <th>incident_desc</th>\n",
       "      <th>incident_desc1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>771319909515038721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id clean_text isincident isaccident isobstacle isdanger  \\\n",
       "0  771319909515038721        NaN      False      False      False    False   \n",
       "\n",
       "  incident_desc incident_desc1  \n",
       "0           NaN            NaN  "
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "df2.head(1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>isincident</th>\n",
       "      <th>isaccident</th>\n",
       "      <th>isobstacle</th>\n",
       "      <th>isdanger</th>\n",
       "      <th>incident_desc</th>\n",
       "      <th>incident_desc1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1013816364220518402</td>\n",
       "      <td>precaucion calle 50 anegada via</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                        clean_text isincident  \\\n",
       "0  1013816364220518402  precaucion calle 50 anegada via        True   \n",
       "\n",
       "  isaccident isobstacle isdanger incident_desc incident_desc1  \n",
       "0      False      False     True           NaN            NaN  "
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df1.drop('Unnamed: 0', axis=1, inplace=True)\r\n",
    "df2.drop('Unnamed: 0', axis=1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "print(len(df1), len(df2), len(df1)+len(df2), len(df))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "69939 87106 157045 157045\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "df = df1.append(df2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "df.head(2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>isincident</th>\n",
       "      <th>isaccident</th>\n",
       "      <th>isobstacle</th>\n",
       "      <th>isdanger</th>\n",
       "      <th>incident_desc</th>\n",
       "      <th>incident_desc1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>771319909515038721</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>789637317946290176</td>\n",
       "      <td>panama Oeste via Centenario</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                    clean_text isincident isaccident  \\\n",
       "0  771319909515038721                          None      False      False   \n",
       "1  789637317946290176  panama Oeste via Centenario        None       None   \n",
       "\n",
       "  isobstacle isdanger incident_desc incident_desc1  \n",
       "0      False    False          None           None  \n",
       "1       None     None          None           None  "
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "## Fill NaN with None (if condition is false, then None)\r\n",
    "df = df.where(pd.notnull(df), None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "len(df[df.isincident==False])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10495"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "len(df[df.isincident==True])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "104995"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "len(df[df.isincident.isnull()])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "41555"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "extract = df.iloc[:, 2:6]\r\n",
    "extract = extract.where(pd.notnull(extract), False)\r\n",
    "df_ex = df.copy()\r\n",
    "df_ex.iloc[:, 2:6] = extract"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "print(len(df_ex[df_ex.isincident==True]), len(df_ex[df_ex.isincident==False]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "104995 52050\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "df_ex.to_csv('data.csv', encoding='utf-8')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}